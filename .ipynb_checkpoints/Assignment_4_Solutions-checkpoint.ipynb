{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade: /100 pts\n",
    "\n",
    "# Assignment 04: Confidence Intervals & The Bootstrap\n",
    "\n",
    "Once you are finished, ensure to complete the following steps.\n",
    "1.  Restart your kernel by clicking 'Kernel' > 'Restart & Run All'.\n",
    "2.  Fix any errors which result from this.\n",
    "3.  Repeat steps 1. and 2. until your notebook runs without errors.\n",
    "4.  Submit your completed notebook to OWL by the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the necessary imports for this homework \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: /10pts \n",
    "In this question, you will construct a confidence interval for the sample mean, not using the normal distribution, but the t-distribution (see end of lecture 4.3), which is more accurate for small sample sizes.  \n",
    "\n",
    "The $100(1-\\alpha)\\%$ confidence interval is \n",
    "\n",
    "$$ \\bar{x} \\pm  t_{1-\\alpha/2, n-1} \\dfrac{\\hat{\\sigma}}{\\sqrt{n}} $$\n",
    "\n",
    "Where $ t_{1-\\alpha/2, n-1}$ is the appropiorate quantile of a Student's t distribution with $n-1$ degrees of freedom.  \n",
    "Write a function called `confidence_interval` which takes as it's argument an array of data called `data` and returns two things:\n",
    "\n",
    "* An estimated mean of `data`, and \n",
    "\n",
    "* The lower and upper bounds of the 95% confidence interval for the mean of `data`.  Ensure these are returned in a numpy array of shape (2,)\n",
    "\n",
    "To get the appropirate quantiles for the t-distribution, you can use `scipy.stats.t`, which implements some statistical functions for the t-distribution.  Take a look at the documentation for `scipy.stats.t`, especially the `ppf` method.\n",
    "\n",
    "Here is the documentation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(data):\n",
    "\n",
    "    n = data.size\n",
    "    t_quantile = t.ppf(1-0.05/2, df=n-1)\n",
    "    estimated_mean = data.mean()\n",
    "    # Note, np.std divides by n and not n-1\n",
    "    # Force it to apply the correct formula by ussing ddof=1\n",
    "    # Alternaively, you can use scipy.stats.sem to compute\n",
    "    #The standard error\n",
    "    estimated_se = data.std(ddof=1)/np.sqrt(data.size)\n",
    "    bounds = estimated_mean + t_quantile*estimated_se*np.array([-1,1])\n",
    "\n",
    "    \n",
    "    return estimated_mean, bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: /15pts\n",
    "\n",
    "The \"95% confidence interval\" is named so because the long term relative frequency of these estimators containing the true estimand is 95%.  That is to say **if I construct 100 95% confidence intervals for the sample mean again and again from the same data generating mechanism, 95 of these intervals I construct will contain the true population mean**.\n",
    "\n",
    "Write a function called `ci_simulation` that runs some simulations to show this is the case.  From a standard normal distirbution, sample 25 observations and construct a confidence interval.  Do this 20 times and plot the intervals using `matplotlib.pyplot.errorbar`.  Color the bar red if the confidence interval does not capture the true mean and blue if it does.  If you are unfamilliar with `matplotlib.pyplot.errorbar`, I highly suggest reading Matplotlib's excellent documentation which has some examples at the bottom of the webpage.\n",
    "\n",
    "If you are unfamilliar with how to sample random numbers, I suggest you look at `numpy.random.normal`.  Try searching for the documentation for that function yourself if you need to.\n",
    "\n",
    "Here is the documentation for `matplotlib.pyplot.errorbar`: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.errorbar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7fda4b282f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mci_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-7fda4b282f97>\u001b[0m in \u001b[0;36mci_simulation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Compute what we need for the CI, namely the mean and the bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfidence_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# color should be blue if it crosses the black line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-734f25426353>\u001b[0m in \u001b[0;36mconfidence_interval\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mt_quantile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mestimated_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Note, np.std divides by n and not n-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ci_simulation():\n",
    "    # Set the random seed to always get the same random numbers. \n",
    "    # This is for Reproducibility. \n",
    "    np.random.seed(4)\n",
    "    \n",
    "    # Create the figure.\n",
    "    fig, ax = plt.subplots(dpi = 120)\n",
    "\n",
    "    # If the interval crosses this line, it should be blue, else red.\n",
    "    ax.axhline(0, color = 'k')\n",
    "\n",
    "    # Do the following 20 times\n",
    "    for i in range(20):\n",
    "\n",
    "        #Draw 25 observations from a standard normal\n",
    "        data = np.random.normal(size = 25)\n",
    "        # Compute what we need for the CI, namely the mean and the bounds\n",
    "        mu,bounds = confidence_interval(data)\n",
    "        \n",
    "        # color should be blue if it crosses the black line\n",
    "        color = 'blue'\n",
    "        if (min(bounds)>0)|(max(bounds)<0):\n",
    "            # but in the case it does not, turn it red\n",
    "            color = 'red'\n",
    "\n",
    "        # Need to get the length of the interval from bounds\n",
    "        interval_len = 1.0/2*(bounds[1] - bounds[0])\n",
    "\n",
    "        ax.errorbar(i, mu, yerr=interval_len, color = color, fmt = 'o')\n",
    "\n",
    "    # This function does not have to return anything\n",
    "    return None\n",
    "\n",
    "ci_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: /8pts\n",
    "\n",
    "If you haven't changed the random seed from 4 and if you implemented the solution correctly, you should one red interval.\n",
    "\n",
    "Answer the following below in no more than 3 sentences:\n",
    "\n",
    "a) How many red intervals did we expect to see?  What is your justifiation for this?\n",
    "\n",
    "Changing the random seed might affect how many red intervals you see.  Try changing the  random seed in your function to 3.  This will yield two red intervals (which is different than what you should expect to see). \n",
    "\n",
    "b) Why does the simulation sometimes deviate from the predicted results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) We expected 1 interval. Only 95% of the intervals should contain the true group mean - 5% not. 5% of 20 is 1.  \n",
    "\n",
    "b) Each simulation of 20 intervals is a random experiment - the mean number of CIs that does not contain the mean should be on, but have binomial distribution with n=20 and p=0.05. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: /10pts\n",
    "\n",
    "Load in the `hockey_draftees_2005.csv` data into pandas. It contains data from hockey players drafted in 2005, including their rank, weight (wt - in pounds) and height (ht - in inches). \n",
    "\n",
    "Fit a linear model of weight (`wt`) explained by height (`ht`) using a linear regression model from sklearn, as done in the lab.  Call your fitted model `model`.  \n",
    "Make a scatter plot of the height (x-axis) against weight (y-axis). \n",
    "Add the predicted values for 66-80 inches. \n",
    "\n",
    "Calculate the residuals from the fit, and report the r-squared for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('hockey_draftees_2005.csv')\n",
    "\n",
    "# Make it and fit the model \n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(np.c_[df.ht],df.wt)\n",
    "\n",
    "# Make the scatter plot \n",
    "ax=sns.scatterplot(x=df.ht,y=df.wt)\n",
    "ax.set_xlabel('Height')\n",
    "ax.set_ylabel('Weight')\n",
    "\n",
    "#Generate and plot the predicted values\n",
    "xp = np.linspace(66, 80, 30)\n",
    "yp = model.predict(np.c_[xp])\n",
    "plt.plot(xp,yp)\n",
    "\n",
    "# Calculate \n",
    "res = df.wt-model.predict(np.c_[df.ht])\n",
    "RSS = np.sum(res**2)\n",
    "TSS = np.sum((df.wt-df.wt.mean())**2)\n",
    "R2 = 1 - RSS/TSS \n",
    "print('Training rsquared is ',R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5:  /15pts\n",
    "### Bootstrap confidence intervals on parameters\n",
    "\n",
    "How confident can we be about the relation between height and weight? \n",
    "To judge this we need confidence intervals let's use the bootstrap.\n",
    "\n",
    "Modify the function `BootstrapCoef` from lab 04 - part 2 to conduct a boostrap analysis for this regression mode; \n",
    "\n",
    "* `data`, which is a dataframe having columns 'weight' and 'height'\n",
    "* `numboot` which is an integer denoting how many bootstrap replications to perform.\n",
    "\n",
    "Write `bootstrap` to perform bootstrap resampling. You can use `pd.DataFrame.sample` with `replace = True` to perform the resampling.  `bootstrap` should return:\n",
    "params: a numpy array of size [numboot,numParams] of bootstraped parameter values. The parameters are the intercept value and the slope from the linear regression. \n",
    "Tip: Note that the intercept can be retrieved from model.intercept_, whereas all the other regression coefficients are stored in model.coef_. \n",
    "\n",
    "Here is the documentation for `pd.DataFrame.sample`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html\n",
    "\n",
    "Then call the function to get 100 boostrap samples for your linear regression model of wt explained by height. \n",
    "Make a joint scatter plot of the parameter value for the intercept and for the slope. \n",
    "Written answer: What do you notice? Why do you think the estimate for the intercept has such a high negative correlation with the slope? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a Bootstrap function that records the fitted models \n",
    "def BootstrapCoef(data,numboot=1000):\n",
    "    regr = sklearn.linear_model.LinearRegression()\n",
    "    numboot = 1000\n",
    "    n = len(data)\n",
    "    theta = np.zeros((numboot,2))    \n",
    "    for i in range(numboot):\n",
    "        d = data.sample(n, replace=True)\n",
    "        X_fit = np.c_[d.ht]\n",
    "        regr.fit(X_fit,d.wt)\n",
    "        theta[i,0]=regr.intercept_\n",
    "        theta[i,1]=regr.coef_\n",
    "    return theta\n",
    "\n",
    "params = BootstrapCoef(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=params[:,0],y=params[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intercept and slope regressors are highly colinear - as we did not subtract the mean of ht before thre regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: /12pts\n",
    "\n",
    "Plot the bootstrap estimates for the slope as a histogram.  Use your samples to compute a 95% confidence interval. Note that the CI should be constructed around the sample estimate of the slope. How can you interpret this confindence interval?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_res = params[:,1]-model.coef_\n",
    "plt.hist(bs_res, edgecolor = 'white', density=True)\n",
    "ci_lower, ci_upper = np.quantile(bs_replicates, [0.025, 0.975])\n",
    "boot_ci = [model.coef_ - ci_upper, \n",
    "           model.coef_ - ci_lower]\n",
    "\n",
    "print('My confidence interval is between', boot_ci[0], ' and ', boot_ci[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written answer: The interval contains the true slope parameter with a probability of 95%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: /15pts\n",
    "Modify the function `BootstrapPred` from lab04 to bootstrap your fit and generate a predict from each of these bootstrapped models.  \n",
    "\n",
    "Draw again a scatter plot of ht against weight. and plot the predictions from the 20 fitted bootstrap models to derive predictions for the height ranging from 60 to 88. Draw all these lines onto your scatter plot. \n",
    "\n",
    "Written answer: Where are we most uncertain in our prediction about the weight of a player? How does the negative correlation between slope and intercept play a role here?  Why is the spread of the prediction in the mean weight so much lower than the variability of our intercept parameter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a Bootstrap function that records the fitted models \n",
    "def BootstrapPred(data,xp):\n",
    "    regr = sklearn.linear_model.LinearRegression()\n",
    "    numboot = 20\n",
    "    n = len(data)\n",
    "    X_pred = np.c_[xp]\n",
    "    y_pred = np.zeros((numboot,X_pred.shape[0]))    \n",
    "\n",
    "    for i in range(numboot):\n",
    "        d = data.sample(n, replace=True)\n",
    "        X_fit = np.c_[d.ht]\n",
    "        regr.fit(X_fit,d.wt)\n",
    "        y_pred[i,:]=regr.predict(X_pred)\n",
    "    return y_pred\n",
    "\n",
    "# Get predictions from 20 bootstrapped models \n",
    "xp = np.linspace(66, 80, 30)\n",
    "YP = BootstrapPred(df,xp)\n",
    "\n",
    "# Make a scatterplot and draw the 20 lines  \n",
    "ax=sns.scatterplot(x=df.ht,y=df.wt)\n",
    "for i in range(20):\n",
    "    plt.plot(xp,YP[i,:])\n",
    "\n",
    "ax.set_xlabel('Height')\n",
    "ax.set_ylabel('Weight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greatest uncertainty we have for the very small and very tall players. All lines agree in their prediction for the players of middle weight. For the lines to cross in the middle of the graph, a large slope needs to have a small intercept and a small slope needs to have a large intercept. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8:  /15pts\n",
    "\n",
    "Now, let's see how well our model performs out of sample.  Load in the `hockey_draftees_test.csv` file into a dataframe.  \n",
    "Use your fitted `model` to make predictions. \n",
    "\n",
    "Make a scatter plot of the test data and superimpose the prediction of the model. \n",
    "To evaluate this prediction, calculate the r-square value for the out of sample (oos) data.  Statsmodels doesn't provide a function to compute r-squared on new data.  You will have to write one yourself or find one that performs the computation for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('hockey_draftees_test.csv')\n",
    "\n",
    "# Make the scatter plot \n",
    "ax=sns.scatterplot(x=df_test.ht,y=df_test.wt)\n",
    "ax.set_xlabel('Height')\n",
    "ax.set_ylabel('Weight')\n",
    "\n",
    "#Generate and plot the predicted values\n",
    "xp = np.linspace(66, 80, 30)\n",
    "yp = model.predict(np.c_[xp])\n",
    "plt.plot(xp,yp)\n",
    "\n",
    "# Now do the prediction for the test data and compute R2\n",
    "y = df_test.wt.values\n",
    "yhat = model.predict(np.c_[df_test.wt])\n",
    "rsquared_oos = 1 - (np.sum((y - yhat)**2)) / np.sum((y - y.mean())**2)\n",
    "print('Out of sample rsquared is ', rsquared_oos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
